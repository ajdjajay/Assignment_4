{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Scrape the details of most viewed videos on YouTube from Wikipedia: Url =https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/ You need to find following details: \n",
    "            \n",
    "            A) Rank \n",
    "            \n",
    "            B) Name \n",
    "            \n",
    "            C) Artist \n",
    "            \n",
    "            D) Upload date E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Chrome webdriver\n",
    "driver = webdriver.Chrome(\"C:/Users/User/Downloads/chromedriver_win32/chromedriver\")\n",
    "\n",
    "# passing the url\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the variable\n",
    "rank = []\n",
    "name = []\n",
    "artist = []\n",
    "date = []\n",
    "views = []\n",
    "data = []\n",
    "\n",
    "\n",
    "# scraping the rank\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[1]'):\n",
    "    rank.append(i.text)\n",
    "\n",
    "# scraping the name of the album\n",
    "for j in driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[2]'):\n",
    "    name.append(j.text)\n",
    "\n",
    "# scraping the artist name\n",
    "for k in driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[3]'):\n",
    "    artist.append(k.text)\n",
    "# scraping views\n",
    "for l in driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[4]'):\n",
    "    views.append(l.text)\n",
    "    \n",
    "# scraping the date\n",
    "for m in driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[5]'):\n",
    "    date.append(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Album Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (in Billion)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[23]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>9,453,134,982</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[25]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7,572,747,360</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[26]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5,781,348,353</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Shape of You\"[27]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5,483,427,541</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"See You Again\"[28]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5,284,905,560</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"Bath Song\"[31]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4,549,294,432</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4,513,879,675 (as of Sep 29, 2021)</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[33]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4,461,096,975</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[34]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4,319,159,452</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Phonics Song with Two Words\"[35]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4,220,180,419</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Gangnam Style\"[36]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4,211,421,413</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Dame Tu Cosita\"[38]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3,633,337,215</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3,565,906,701</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Sorry\"[40]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3,474,094,697</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3,444,786,615</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Counting Stars\"[42]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3,412,577,920</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Thinking Out Loud\"[43]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3,337,279,340</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Wheels on the Bus\"[44]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3,291,808,512</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Dark Horse\"[45]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3,155,611,442</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Faded\"[46]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3,155,489,927</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Girls Like You\"[47]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3,143,116,042</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3,105,926,931</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Bailando\"[49]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3,105,539,316</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3,104,230,107</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3,090,217,295</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Axel F\"[52]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3,035,828,739</td>\n",
       "      <td>June 17, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Mi Gente\"[53]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>2,986,493,839</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Perfect\"[54]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2,974,982,274</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[55]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>2,962,613,841</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Hello\"[56]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>2,889,107,727</td>\n",
       "      <td>October 23, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Album Name  \\\n",
       "0     1                           \"Baby Shark Dance\"[23]   \n",
       "1     2                                  \"Despacito\"[25]   \n",
       "2     3                       \"Johny Johny Yes Papa\"[26]   \n",
       "3     4                               \"Shape of You\"[27]   \n",
       "4     5                              \"See You Again\"[28]   \n",
       "5     6                                  \"Bath Song\"[31]   \n",
       "6     7  \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "7     8   \"Masha and the Bear – Recipe for Disaster\"[33]   \n",
       "8     9                                \"Uptown Funk\"[34]   \n",
       "9    10                \"Phonics Song with Two Words\"[35]   \n",
       "10   11                              \"Gangnam Style\"[36]   \n",
       "11   12                             \"Dame Tu Cosita\"[38]   \n",
       "12   13                                      \"Sugar\"[39]   \n",
       "13   14                                      \"Sorry\"[40]   \n",
       "14   15                                       \"Roar\"[41]   \n",
       "15   16                             \"Counting Stars\"[42]   \n",
       "16   17                          \"Thinking Out Loud\"[43]   \n",
       "17   18                          \"Wheels on the Bus\"[44]   \n",
       "18   19                                 \"Dark Horse\"[45]   \n",
       "19   20                                      \"Faded\"[46]   \n",
       "20   21                             \"Girls Like You\"[47]   \n",
       "21   22                                    \"Lean On\"[48]   \n",
       "22   23                                   \"Bailando\"[49]   \n",
       "23   24                               \"Shake It Off\"[50]   \n",
       "24   25                                 \"Let Her Go\"[51]   \n",
       "25   26                                     \"Axel F\"[52]   \n",
       "26   27                                   \"Mi Gente\"[53]   \n",
       "27   28                                    \"Perfect\"[54]   \n",
       "28   29           \"Waka Waka (This Time for Africa)\"[55]   \n",
       "29   30                                      \"Hello\"[56]   \n",
       "\n",
       "                                         Artist  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "1                                    Luis Fonsi   \n",
       "2                                   LooLoo Kids   \n",
       "3                                    Ed Sheeran   \n",
       "4                                   Wiz Khalifa   \n",
       "5                    Cocomelon – Nursery Rhymes   \n",
       "6                                   Miroshka TV   \n",
       "7                                    Get Movies   \n",
       "8                                   Mark Ronson   \n",
       "9                                     ChuChu TV   \n",
       "10                                          Psy   \n",
       "11                                    El Chombo   \n",
       "12                                     Maroon 5   \n",
       "13                                Justin Bieber   \n",
       "14                                   Katy Perry   \n",
       "15                                  OneRepublic   \n",
       "16                                   Ed Sheeran   \n",
       "17                   Cocomelon – Nursery Rhymes   \n",
       "18                                   Katy Perry   \n",
       "19                                  Alan Walker   \n",
       "20                                     Maroon 5   \n",
       "21                                  Major Lazer   \n",
       "22                             Enrique Iglesias   \n",
       "23                                 Taylor Swift   \n",
       "24                                    Passenger   \n",
       "25                                   Crazy Frog   \n",
       "26                                     J Balvin   \n",
       "27                                   Ed Sheeran   \n",
       "28                                      Shakira   \n",
       "29                                        Adele   \n",
       "\n",
       "                    Views (in Billion)        Upload Date  \n",
       "0                        9,453,134,982      June 17, 2016  \n",
       "1                        7,572,747,360   January 12, 2017  \n",
       "2                        5,781,348,353    October 8, 2016  \n",
       "3                        5,483,427,541   January 30, 2017  \n",
       "4                        5,284,905,560      April 6, 2015  \n",
       "5                        4,549,294,432        May 2, 2018  \n",
       "6   4,513,879,675 (as of Sep 29, 2021)  February 27, 2018  \n",
       "7                        4,461,096,975   January 31, 2012  \n",
       "8                        4,319,159,452  November 19, 2014  \n",
       "9                        4,220,180,419      March 6, 2014  \n",
       "10                       4,211,421,413      July 15, 2012  \n",
       "11                       3,633,337,215      April 5, 2018  \n",
       "12                       3,565,906,701   January 14, 2015  \n",
       "13                       3,474,094,697   October 22, 2015  \n",
       "14                       3,444,786,615  September 5, 2013  \n",
       "15                       3,412,577,920       May 31, 2013  \n",
       "16                       3,337,279,340    October 7, 2014  \n",
       "17                       3,291,808,512       May 24, 2018  \n",
       "18                       3,155,611,442  February 20, 2014  \n",
       "19                       3,155,489,927   December 3, 2015  \n",
       "20                       3,143,116,042       May 31, 2018  \n",
       "21                       3,105,926,931     March 22, 2015  \n",
       "22                       3,105,539,316     April 11, 2014  \n",
       "23                       3,104,230,107    August 18, 2014  \n",
       "24                       3,090,217,295      July 25, 2012  \n",
       "25                       3,035,828,739      June 17, 2009  \n",
       "26                       2,986,493,839      June 29, 2017  \n",
       "27                       2,974,982,274   November 9, 2017  \n",
       "28                       2,962,613,841       June 4, 2010  \n",
       "29                       2,889,107,727   October 23, 2015  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube = pd.DataFrame({'Rank': rank,\n",
    "                       'Album Name': name,\n",
    "                       'Artist': artist,\n",
    "                       'Views (in Billion)': views,\n",
    "                       'Upload Date': date})\n",
    "youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/. You need to find following details: \n",
    "        \n",
    "        A) Match title (I.e. 1st ODI) \n",
    "        \n",
    "        B) Series \n",
    "        \n",
    "        C) Place \n",
    "        \n",
    "        D) Date \n",
    "        \n",
    "        E) Time Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Chrome webdriver\n",
    "driver = webdriver.Chrome(\"C:/Users/User/Downloads/chromedriver_win32/chromedriver\")\n",
    "# opening the url\n",
    "driver.get('https://www.bcci.tv')\n",
    "\n",
    "# getiing the internation fixture page\n",
    "page = driver.find_element_by_xpath('/html/body/footer/div/nav/ul/li[2]/ul/li[1]/a')\n",
    "page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing details\n",
    "title = []\n",
    "series = []\n",
    "place = []\n",
    "date = []\n",
    "time = []\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "# scraping the title\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__format']\"):\n",
    "    title.append(i.text)\n",
    "\n",
    "# scraping series name\n",
    "for j in driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\"):\n",
    "    series.append(j.text)\n",
    "    \n",
    "# scraping the place\n",
    "for k in driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\"):\n",
    "    place.append(k.text)\n",
    "    \n",
    "# scraping date of the match\n",
    "for l in driver.find_elements_by_xpath(\"//span[@class='fixture__date']\"):\n",
    "    list1.append(l.text)\n",
    "for m in driver.find_elements_by_xpath(\"//span[@class='fixture__month']\"):\n",
    "    list2.append(m.text)\n",
    "date = [i + j for i, j in zip(list1, list2)]\n",
    "\n",
    "# scraping time\n",
    "for n in driver.find_elements_by_xpath(\"//span[@class='fixture__time']\"):\n",
    "    time.append(n.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture = pd.DataFrame({})\n",
    "fixture['Match Title'] = title\n",
    "fixture['Series'] = series\n",
    "fixture['Place'] = place\n",
    "fixture['Date'] = date\n",
    "fixture['Time'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Dubai International Stadium, Dubai</td>\n",
       "      <td>24OCTOBER</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Dubai International Stadium, Dubai</td>\n",
       "      <td>31OCTOBER</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Zayed Cricket Stadium, Abu Dhabi</td>\n",
       "      <td>03NOVEMBER</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Dubai International Stadium, Dubai</td>\n",
       "      <td>05NOVEMBER</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Dubai International Stadium, Dubai</td>\n",
       "      <td>08NOVEMBER</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T20I</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>Sawai Mansingh Stadium, Jaipur</td>\n",
       "      <td>17NOVEMBER</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T20I</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>JSCA International Stadium Complex, Ranchi</td>\n",
       "      <td>19NOVEMBER</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T20I</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>21NOVEMBER</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>Green Park, Kanpur</td>\n",
       "      <td>25NOVEMBER</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>03DECEMBER</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>New Wanderers Stadium, Johannesburg</td>\n",
       "      <td>17DECEMBER</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>Supersport Park, Centurion</td>\n",
       "      <td>26DECEMBER</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>New Wanderers Stadium, Johannesburg</td>\n",
       "      <td>03JANUARY</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>Boland Park, Paarl</td>\n",
       "      <td>11JANUARY</td>\n",
       "      <td>14:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>14JANUARY</td>\n",
       "      <td>14:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>16JANUARY</td>\n",
       "      <td>14:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>19JANUARY</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>21JANUARY</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>Boland Park, Paarl</td>\n",
       "      <td>23JANUARY</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>Boland Park, Paarl</td>\n",
       "      <td>26JANUARY</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title                          Series  \\\n",
       "0         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "1         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "2         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "3         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "4         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "5         T20I        INDIA V NEW ZEALAND 2021   \n",
       "6         T20I        INDIA V NEW ZEALAND 2021   \n",
       "7         T20I        INDIA V NEW ZEALAND 2021   \n",
       "8         TEST        INDIA V NEW ZEALAND 2021   \n",
       "9         TEST        INDIA V NEW ZEALAND 2021   \n",
       "10        TEST  SOUTH AFRICA V INDIA 2021/2022   \n",
       "11        TEST  SOUTH AFRICA V INDIA 2021/2022   \n",
       "12        TEST  SOUTH AFRICA V INDIA 2021/2022   \n",
       "13         ODI  SOUTH AFRICA V INDIA 2021/2022   \n",
       "14         ODI  SOUTH AFRICA V INDIA 2021/2022   \n",
       "15         ODI  SOUTH AFRICA V INDIA 2021/2022   \n",
       "16        T20I  SOUTH AFRICA V INDIA 2021/2022   \n",
       "17        T20I  SOUTH AFRICA V INDIA 2021/2022   \n",
       "18        T20I  SOUTH AFRICA V INDIA 2021/2022   \n",
       "19        T20I  SOUTH AFRICA V INDIA 2021/2022   \n",
       "\n",
       "                                         Place        Date       Time  \n",
       "0           Dubai International Stadium, Dubai   24OCTOBER  19:30 IST  \n",
       "1           Dubai International Stadium, Dubai   31OCTOBER  19:30 IST  \n",
       "2             Zayed Cricket Stadium, Abu Dhabi  03NOVEMBER  19:30 IST  \n",
       "3           Dubai International Stadium, Dubai  05NOVEMBER  19:30 IST  \n",
       "4           Dubai International Stadium, Dubai  08NOVEMBER  19:30 IST  \n",
       "5               Sawai Mansingh Stadium, Jaipur  17NOVEMBER  19:00 IST  \n",
       "6   JSCA International Stadium Complex, Ranchi  19NOVEMBER  19:00 IST  \n",
       "7                        Eden Gardens, Kolkata  21NOVEMBER  19:00 IST  \n",
       "8                           Green Park, Kanpur  25NOVEMBER  09:30 IST  \n",
       "9                     Wankhede Stadium, Mumbai  03DECEMBER  09:30 IST  \n",
       "10         New Wanderers Stadium, Johannesburg  17DECEMBER  13:30 IST  \n",
       "11                  Supersport Park, Centurion  26DECEMBER  13:30 IST  \n",
       "12         New Wanderers Stadium, Johannesburg   03JANUARY  13:30 IST  \n",
       "13                          Boland Park, Paarl   11JANUARY  14:00 IST  \n",
       "14                         Newlands, Cape Town   14JANUARY  14:00 IST  \n",
       "15                         Newlands, Cape Town   16JANUARY  14:00 IST  \n",
       "16                         Newlands, Cape Town   19JANUARY  19:30 IST  \n",
       "17                         Newlands, Cape Town   21JANUARY  19:30 IST  \n",
       "18                          Boland Park, Paarl   23JANUARY  19:30 IST  \n",
       "19                          Boland Park, Paarl   26JANUARY  19:30 IST  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/ You need to find following details: \n",
    "\n",
    "A) Name \n",
    "\n",
    "B) Description Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Chrome webdriver\n",
    "driver = webdriver.Chrome(\"C:/Users/User/Downloads/chromedriver_win32/chromedriver\")\n",
    "# opening url\n",
    "driver.get('https://www.guru99.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d986c0c6a315>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# locating search input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msearch_inp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter the topic: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mserach_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"gsc-i-id2\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mserach_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_inp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"___gcse_1\"]/div/div/form/table/tbody/tr/td[2]/button'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# locating search input\n",
    "search_inp = input(\"Enter the topic: \")\n",
    "serach_bar = driver.find_element_by_xpath('//*[@id=\"gsc-i-id2\"]')\n",
    "serach_bar.send_keys(search_inp)\n",
    "driver.find_element_by_xpath('//*[@id=\"___gcse_1\"]/div/div/form/table/tbody/tr/td[2]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ You have to find following details: A) Rank B) State C) GSDP at current price (19-20) D) GSDP at current price (18-19) E) Share(18-19) F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Chrome webdriver\n",
    "driver = webdriver.Chrome(\"C:/Users/User/Downloads/chromedriver_win32/chromedriver\")\n",
    "# opening url\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the indian GDP page\n",
    "a = driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "driver.get(a.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = []\n",
    "state = []\n",
    "gsdp_1920 = []\n",
    "gsdp_1819 = []\n",
    "share = []\n",
    "gdp = []\n",
    "\n",
    "# scraping rank\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[1]'):\n",
    "    rank.append(i.text)\n",
    "\n",
    "#scraping state\n",
    "for j in driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[2]'):\n",
    "    state.append(j.text)\n",
    "\n",
    "# scraping GSDP 19-20\n",
    "for k in driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[3]'):\n",
    "    gsdp_1920.append(k.text)\n",
    "    \n",
    "# scraping GSDP 18-19\n",
    "for l in driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[4]'):\n",
    "    gsdp_1819.append(l.text)\n",
    "    \n",
    "# scraping share\n",
    "for m in driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[5]'):\n",
    "    share.append(m.text)\n",
    "    \n",
    "# scraping GDP\n",
    "for n in driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[6]'):\n",
    "    gdp.append(n.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price(19-20)</th>\n",
       "      <th>GSDP at current price(18-19)</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP at current price(19-20)  \\\n",
       "0     1                Maharashtra                            -   \n",
       "1     2                 Tamil Nadu                    1,845,853   \n",
       "2     3              Uttar Pradesh                    1,687,818   \n",
       "3     4                    Gujarat                            -   \n",
       "4     5                  Karnataka                    1,631,977   \n",
       "5     6                West Bengal                    1,253,832   \n",
       "6     7                  Rajasthan                    1,020,989   \n",
       "7     8             Andhra Pradesh                      972,782   \n",
       "8     9                  Telangana                      969,604   \n",
       "9    10             Madhya Pradesh                      906,672   \n",
       "10   11                     Kerala                            -   \n",
       "11   12                      Delhi                      856,112   \n",
       "12   13                    Haryana                      831,610   \n",
       "13   14                      Bihar                      611,804   \n",
       "14   15                     Punjab                      574,760   \n",
       "15   16                     Odisha                      521,275   \n",
       "16   17                      Assam                            -   \n",
       "17   18               Chhattisgarh                      329,180   \n",
       "18   19                  Jharkhand                      328,598   \n",
       "19   20                Uttarakhand                            -   \n",
       "20   21            Jammu & Kashmir                            -   \n",
       "21   22           Himachal Pradesh                      165,472   \n",
       "22   23                        Goa                       80,449   \n",
       "23   24                    Tripura                       55,984   \n",
       "24   25                 Chandigarh                            -   \n",
       "25   26                 Puducherry                       38,253   \n",
       "26   27                  Meghalaya                       36,572   \n",
       "27   28                     Sikkim                       32,496   \n",
       "28   29                    Manipur                       31,790   \n",
       "29   30                   Nagaland                            -   \n",
       "30   31          Arunachal Pradesh                            -   \n",
       "31   32                    Mizoram                       26,503   \n",
       "32   33  Andaman & Nicobar Islands                            -   \n",
       "\n",
       "   GSDP at current price(18-19)   Share      GDP  \n",
       "0                     2,632,792  13.94%  399.921  \n",
       "1                     1,630,208   8.63%  247.629  \n",
       "2                     1,584,764   8.39%  240.726  \n",
       "3                     1,502,899   7.96%  228.290  \n",
       "4                     1,493,127   7.91%  226.806  \n",
       "5                     1,089,898   5.77%  165.556  \n",
       "6                       942,586   4.99%  143.179  \n",
       "7                       862,957   4.57%  131.083  \n",
       "8                       861,031   4.56%  130.791  \n",
       "9                       809,592   4.29%  122.977  \n",
       "10                      781,653   4.14%  118.733  \n",
       "11                      774,870   4.10%  117.703  \n",
       "12                      734,163   3.89%  111.519  \n",
       "13                      530,363   2.81%   80.562  \n",
       "14                      526,376   2.79%   79.957  \n",
       "15                      487,805   2.58%   74.098  \n",
       "16                      315,881   1.67%   47.982  \n",
       "17                      304,063   1.61%   46.187  \n",
       "18                      297,204   1.57%   45.145  \n",
       "19                      245,895   1.30%   37.351  \n",
       "20                      155,956   0.83%   23.690  \n",
       "21                      153,845   0.81%   23.369  \n",
       "22                       73,170   0.39%   11.115  \n",
       "23                       49,845   0.26%    7.571  \n",
       "24                       42,114   0.22%    6.397  \n",
       "25                       34,433   0.18%    5.230  \n",
       "26                       33,481   0.18%    5.086  \n",
       "27                       28,723   0.15%    4.363  \n",
       "28                       27,870   0.15%    4.233  \n",
       "29                       27,283   0.14%    4.144  \n",
       "30                       24,603   0.13%    3.737  \n",
       "31                       22,287   0.12%    3.385  \n",
       "32                            -       -        -  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.DataFrame({})\n",
    "stats['Rank'] = rank\n",
    "stats['State'] = state\n",
    "stats['GSDP at current price(19-20)'] = gsdp_1920\n",
    "stats['GSDP at current price(18-19)'] = gsdp_1819\n",
    "stats['Share'] = share\n",
    "stats['GDP'] = gdp\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-Scrape the details of trending repositories on Github.com. Url = https://github.com/ You have to find the following details: \n",
    "\n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Chrome webdriver\n",
    "driver = webdriver.Chrome('C:/Users/User/Downloads/chromedriver_win32/chromedriver')\n",
    "# opening the url\n",
    "driver.get('https://www.github.com')\n",
    "\n",
    "trending = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a')\n",
    "trending = trending.get_attribute('href')\n",
    "driver.get(trending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vreating variable to store the data\n",
    "title = []\n",
    "desc = []\n",
    "contri = []\n",
    "lang = []\n",
    "url = []\n",
    "\n",
    "#scraping title\n",
    "for h in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\"):\n",
    "    title.append(h.text[h.text.find(\"/\")+1:])\n",
    "\n",
    "# sraping language used\n",
    "loop = range(1,26)\n",
    "for i in loop:\n",
    "    try:\n",
    "        a = driver.find_element_by_xpath('//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article['+str(i)+']/div[2]/span[1]/span[2]')\n",
    "        lang.append(a.text)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')\n",
    "\n",
    "# scraping contribution count\n",
    "for j in driver.find_elements_by_xpath(\"//div[@class='f6 color-text-secondary mt-2']/a[2]\"):\n",
    "    contri.append(j.text)\n",
    "    \n",
    "# scraping title and description\n",
    "for k in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\"):\n",
    "    url.append(k.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Contributord count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy-Robot</td>\n",
       "      <td>389</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real-ESRGAN</td>\n",
       "      <td>370</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sm64ex-ios</td>\n",
       "      <td>12</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethereum-org-website</td>\n",
       "      <td>1,470</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>useful-custom-react-hooks</td>\n",
       "      <td>130</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>algo</td>\n",
       "      <td>1,922</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>promote-your-next-startup</td>\n",
       "      <td>116</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>awesome-actions</td>\n",
       "      <td>1,009</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google-Chinese-Results-Blocklist</td>\n",
       "      <td>157</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L-ink_Card</td>\n",
       "      <td>1,384</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>iptv</td>\n",
       "      <td>3,603</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>peng-zhihui.github.io</td>\n",
       "      <td>117</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExplorerPatcher</td>\n",
       "      <td>21</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>openwrt</td>\n",
       "      <td>6,302</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>go-zero</td>\n",
       "      <td>1,388</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EIPs</td>\n",
       "      <td>2,840</td>\n",
       "      <td>Solidity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>30,136</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>docs</td>\n",
       "      <td>27,598</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gop</td>\n",
       "      <td>402</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>eattheblocks</td>\n",
       "      <td>1,848</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lotus</td>\n",
       "      <td>894</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bevy</td>\n",
       "      <td>950</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ghidra</td>\n",
       "      <td>3,807</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>go</td>\n",
       "      <td>13,399</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ourboard</td>\n",
       "      <td>13</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Repository title Contributord count Language Used\n",
       "0                         Dummy-Robot                389             -\n",
       "1                         Real-ESRGAN                370        Python\n",
       "2                          sm64ex-ios                 12             C\n",
       "3                ethereum-org-website              1,470    JavaScript\n",
       "4           useful-custom-react-hooks                130    JavaScript\n",
       "5                                algo              1,922        Python\n",
       "6           promote-your-next-startup                116             -\n",
       "7                     awesome-actions              1,009             -\n",
       "8    Google-Chinese-Results-Blocklist                157             -\n",
       "9                          L-ink_Card              1,384             C\n",
       "10                               iptv              3,603    JavaScript\n",
       "11              peng-zhihui.github.io                117          HTML\n",
       "12                    ExplorerPatcher                 21             C\n",
       "13                            openwrt              6,302             C\n",
       "14                            go-zero              1,388            Go\n",
       "15                               EIPs              2,840      Solidity\n",
       "16                            bitcoin             30,136           C++\n",
       "17                               docs             27,598    JavaScript\n",
       "18                                gop                402            Go\n",
       "19                       eattheblocks              1,848    JavaScript\n",
       "20                              lotus                894            Go\n",
       "21                               bevy                950          Rust\n",
       "22                             ghidra              3,807          Java\n",
       "23                                 go             13,399            Go\n",
       "24                           ourboard                 13    TypeScript"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github = pd.DataFrame({'Repository title': title,\n",
    "                      'Contributord count': contri,\n",
    "                      'Language Used': lang})\n",
    "github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-Scrape the details of top 100 songs on billboard.com. Url = https://www.billboard.com/ You have to find the following details: A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board Note: - From the home page you have to click on the charts option then hot 100-page link through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Chrome webdriver\n",
    "driver = webdriver.Chrome('C:/Users/User/Downloads/chromedriver_win32/chromedriver')\n",
    "# opening url\n",
    "driver.get('https://www.billboard.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the hot 100 bar\n",
    "driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[2]/nav/ul/li[3]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating variable to store the data\n",
    "song = []\n",
    "artist = []\n",
    "w_rank = []\n",
    "p_rank = []\n",
    "on_board = []\n",
    "\n",
    "#scraping song name\n",
    "for i in driver.find_elements_by_xpath('//span[@class=\"chart-element__information__song text--truncate color--primary\"]'):\n",
    "    song.append(i.text)\n",
    "    \n",
    "# scarping artist name\n",
    "for j in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\"):\n",
    "    artist.append(j.text)\n",
    "    \n",
    "#scraping last week rank\n",
    "for k in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\"):\n",
    "    w_rank.append(k.text)\n",
    "    \n",
    "#scraping peak rank\n",
    "for l in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\"):\n",
    "    p_rank.append(l.text)\n",
    "    \n",
    "#scraping weeks on board\n",
    "for m in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\"):\n",
    "    on_board.append(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My Universe</td>\n",
       "      <td>Coldplay x BTS</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Industry Baby</td>\n",
       "      <td>Lil Nas X &amp; Jack Harlow</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Way 2 Sexy</td>\n",
       "      <td>Drake Featuring Future &amp; Young Thug</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fancy Like</td>\n",
       "      <td>Walker Hayes</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Pipe Down</td>\n",
       "      <td>Drake</td>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Papi's Home</td>\n",
       "      <td>Drake</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chosen</td>\n",
       "      <td>Blxst &amp; Tyga Featuring Ty Dolla $ign</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Toxic Punk</td>\n",
       "      <td>YoungBoy Never Broke Again</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Moon</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>76</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Song Name                           Artist Name Last week rank  \\\n",
       "0     My Universe                        Coldplay x BTS              -   \n",
       "1            Stay         The Kid LAROI & Justin Bieber              1   \n",
       "2   Industry Baby               Lil Nas X & Jack Harlow              2   \n",
       "3      Way 2 Sexy   Drake Featuring Future & Young Thug              3   \n",
       "4      Fancy Like                          Walker Hayes              5   \n",
       "..            ...                                   ...            ...   \n",
       "95      Pipe Down                                 Drake             68   \n",
       "96    Papi's Home                                 Drake             66   \n",
       "97         Chosen  Blxst & Tyga Featuring Ty Dolla $ign              -   \n",
       "98     Toxic Punk            YoungBoy Never Broke Again              -   \n",
       "99           Moon                            Kanye West             76   \n",
       "\n",
       "   Peak rank Weeks on board  \n",
       "0          1              1  \n",
       "1          1             12  \n",
       "2          2             10  \n",
       "3          1              4  \n",
       "4          5             15  \n",
       "..       ...            ...  \n",
       "95        14              4  \n",
       "96         8              4  \n",
       "97        98              1  \n",
       "98        99              1  \n",
       "99        17              5  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billboard = pd.DataFrame({'Song Name': song,\n",
    "                         'Artist Name': artist,\n",
    "                         'Last week rank': w_rank,\n",
    "                         'Peak rank': p_rank,\n",
    "                         'Weeks on board': on_board})\n",
    "Billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/ You have to find the following details: A) Name B) Designation C) Company D) Skills they hire for E) Location Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills_they_hire_for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Modeling, Data Wrangling, seaborn, eda, p...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Narasimha</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Narasimha</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Step Next Private Limited</td>\n",
       "      <td>Director</td>\n",
       "      <td>Step Next Private Limited</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name                  Designation  \\\n",
       "0                           Aakash Harit                   HR Manager   \n",
       "1                   Data Science Network            Company Recruiter   \n",
       "2                   shravan Kumar Gaddam                   Company HR   \n",
       "3          Shore Infotech India Pvt. Ltd            Company Recruiter   \n",
       "4               MARSIAN Technologies LLP            Company Recruiter   \n",
       "5               MARSIAN Technologies LLP                  Founder CEO   \n",
       "6                           Anik Agrawal  Recruitment Lead Consultant   \n",
       "7  Enerlytics Software Solutions Pvt Ltd            Programme Manager   \n",
       "8                              Narasimha             HR Administrator   \n",
       "9              Step Next Private Limited                     Director   \n",
       "\n",
       "                                 Company  \\\n",
       "0                           Aakash Harit   \n",
       "1                   Data Science Network   \n",
       "2                   shravan Kumar Gaddam   \n",
       "3          Shore Infotech India Pvt. Ltd   \n",
       "4               MARSIAN Technologies LLP   \n",
       "5               MARSIAN Technologies LLP   \n",
       "6                           Anik Agrawal   \n",
       "7  Enerlytics Software Solutions Pvt Ltd   \n",
       "8                              Narasimha   \n",
       "9              Step Next Private Limited   \n",
       "\n",
       "                                Skills_they_hire_for                  Location  \n",
       "0  Classic ASP Developer, Internet Marketing Prof...                     Delhi  \n",
       "1  .Net, Java, Data Science, Linux Administration...  Hyderabad / Secunderabad  \n",
       "2  Data Science, Artificial Intelligence, Machine...                      Pune  \n",
       "3  Mean Stack, javascript, angularjs, mongodb, We...                 Ahmedabad  \n",
       "4  Data Modeling, Data Wrangling, seaborn, eda, p...  Hyderabad / Secunderabad  \n",
       "5  Hadoop, Spark, Digital Strategy, Data Architec...             UK - (london)  \n",
       "6  Analytics, Business Intelligence, Business Ana...         Vadodara / Baroda  \n",
       "7                                       Data Science                   Chennai  \n",
       "8  Machine Learning, algorithms, Go Getter, Compu...                Trivandrum  \n",
       "9  Technical Training, Software Development, Pres...                    Indore  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"C:/Users/User/Downloads/chromedriver_win32/chromedriver\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.naukri.com/hr-recruiters-consultants\"\n",
    "driver.get(url)\n",
    "\n",
    "# entering “Data Analyst” in “Skill,Designations,Companies” field.\n",
    "search_field=driver.find_element_by_xpath(\"//input[@class='sugInp']\") #job search bar\n",
    "search_field.send_keys(\"Data Science\")\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_id(\"qsbFormBtn\")\n",
    "search_button.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills_they_hire_for=[]\n",
    "Location=[]\n",
    "\n",
    "#scraping the job-titles\n",
    "title=driver.find_elements_by_xpath(\"//p[@class='highlightable']//a\")[:48]\n",
    "for i in title:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "        \n",
    "#scraping the Designation\n",
    "deg=driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")[:48]\n",
    "for i in deg:\n",
    "    if i.text is None :\n",
    "        Designation.append(\"--\") \n",
    "    else:\n",
    "        Designation.append(i.text)\n",
    "               \n",
    "#scraping the Company\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='ellipsis']\")[:48]\n",
    "for i in comp:\n",
    "    if i.text is None :\n",
    "        Company.append(\"--\") \n",
    "    else:\n",
    "        Company.append(i.text)\n",
    "               \n",
    "#scraping the Skills_they_hire_for\n",
    "skills=driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\")[:48]\n",
    "for i in skills:\n",
    "    if i.text is None :\n",
    "        Skills_they_hire_for.append(\"--\") \n",
    "    else:\n",
    "        Skills_they_hire_for.append(i.text)\n",
    "        \n",
    "#scraping the Location\n",
    "loc=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")[:48]\n",
    "for i in loc:\n",
    "    if i.text is None :\n",
    "        Location.append(\"--\") \n",
    "    else:\n",
    "        Location.append(i.text)  \n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Name\":Name,\"Designation\":Designation,\"Company\":Company,\"Skills_they_hire_for\":Skills_they_hire_for,\"Location\":Location})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"C:/Users/User/Downloads/chromedriver_win32/chromedriver\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#scraping Books Name\n",
    "book=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "for i in book:\n",
    "    if i.text is None :\n",
    "        Book_name.append(\"--\") \n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "                \n",
    "# scraping Author name\n",
    "author=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "for i in author:\n",
    "    if i.text is None :\n",
    "        Author_name.append(\"--\") \n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "        \n",
    "# scraping Volumes Sold\n",
    "volume=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "for i in volume:\n",
    "    if i.text is None :\n",
    "        Volumes_sold.append(\"--\") \n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "                \n",
    "# scraping Publisher\n",
    "publisher=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "for i in publisher:\n",
    "    if i.text is None :\n",
    "        Publisher.append(\"--\") \n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "               \n",
    "# scraping Genre\n",
    "genre = driver.find_elements_by_xpath((\"//td[@class='last left']\"))\n",
    "for i in genre:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\")\n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Book_name\":Book_name[1::5],\"Author_name\":Author_name[2::5],\"Volumes_sold\":Volumes_sold[3::5],\"Publisher\":Publisher[4::5],\"Genre\":Genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9-Scrape the details most watched tv series of all time from imdb.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,882,783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>916,145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>904,507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>270,951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>231,332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>45,907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>56,778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>177,382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>36,895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>203,838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  1,882,783  \n",
       "1    51 min     8.7    916,145  \n",
       "2    44 min     8.2    904,507  \n",
       "3    60 min     7.5    270,951  \n",
       "4    43 min     7.6    231,332  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     45,907  \n",
       "96   50 min     7.8     56,778  \n",
       "97   42 min     8.1    177,382  \n",
       "98   45 min     7.1     36,895  \n",
       "99  572 min     8.6    203,838  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"C:/Users/User/Downloads/chromedriver_win32/chromedriver\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "# scraping top Movies name\n",
    "name = driver.find_elements_by_xpath((\"//h3[@class='lister-item-header']//a\"))\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "        \n",
    "#scraping year span       \n",
    "year = driver.find_elements_by_xpath((\"//span[@class='lister-item-year text-muted unbold']\"))\n",
    "for i in year:       \n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text) \n",
    "        \n",
    "#scraping genre       \n",
    "gen = driver.find_elements_by_xpath((\"//span[@class='genre']\"))\n",
    "for i in gen :       \n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\") \n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "        \n",
    "#scraping run time\n",
    "time = driver.find_elements_by_xpath((\"//span[@class='runtime']\"))\n",
    "for i in time:       \n",
    "    if i.text is None :\n",
    "        Run_time.append(\"--\") \n",
    "    else:\n",
    "        Run_time.append(i.text)\n",
    "\n",
    "#scraping ratings\n",
    "rate = driver.find_elements_by_xpath((\"//div[@class='ipl-rating-star small']\"))\n",
    "for i in rate:       \n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        Ratings.append(i.text)\n",
    "\n",
    "#scraping votes\n",
    "vote = driver.find_elements_by_xpath((\"//span[@name='nv']\"))\n",
    "for i in vote:       \n",
    "    if i.text is None :\n",
    "        Votes.append(\"--\") \n",
    "    else:\n",
    "        Votes.append(i.text)\n",
    "\n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Name\":Name,\"Year_span\":Year_span,\"Genre\":Genre,\"Run_time\":Run_time,\"Ratings\":Ratings,\"Votes\":Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading Chrome webdriver\n",
    "driver = webdriver.Chrome('C:/Users/User/Downloads/chromedriver_win32/chromedriver')\n",
    "# opening the url\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening view all dataset page\n",
    "driver.find_element_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating variables to store the data\n",
    "name = []\n",
    "data_type = []\n",
    "task = []\n",
    "attribute = []\n",
    "instance = []\n",
    "n_attribute = []\n",
    "year = []\n",
    "\n",
    "#scraping the dataset name\n",
    "for i in driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]'):\n",
    "    name.append(i.text)\n",
    "    \n",
    "#scraping the data type\n",
    "for j in driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]'):\n",
    "    data_type.append(j.text)\n",
    "    \n",
    "#scraping the task\n",
    "for k in driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]'):\n",
    "    task.append(k.text)\n",
    "    \n",
    "#scraping the attribute type\n",
    "for l in driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]'):\n",
    "    attribute.append(l.text)\n",
    "    \n",
    "#scraping the number of instance\n",
    "for m in driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]'):\n",
    "    instance.append(m.text)\n",
    "    \n",
    "#scraping the number of attribute\n",
    "for n in driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]'):\n",
    "    n_attribute.append(n.text)\n",
    "    \n",
    "#scraping the year\n",
    "for o in driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]'):\n",
    "    year.append(o.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>Number of Instance</th>\n",
       "      <th>Number of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Data Types</td>\n",
       "      <td>Default Task</td>\n",
       "      <td>Attribute Types</td>\n",
       "      <td># Instances</td>\n",
       "      <td># Attributes</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name      Data Type                  Task  \\\n",
       "0                                  Name     Data Types          Default Task   \n",
       "1                               Abalone  Multivariate        Classification    \n",
       "2                                 Adult  Multivariate        Classification    \n",
       "3                             Annealing  Multivariate        Classification    \n",
       "4          Anonymous Microsoft Web Data                 Recommender-Systems    \n",
       "..                                  ...            ...                   ...   \n",
       "584    in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "585                 Gait Classification  Multivariate        Classification    \n",
       "586           Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587           Wikipedia Math Essentials   Time-Series            Regression    \n",
       "588        Synchronous Machine Data Set  Multivariate            Regression    \n",
       "\n",
       "                  Attribute Type Number of Instance Number of Attribute   Year  \n",
       "0                Attribute Types        # Instances        # Attributes   Year  \n",
       "1    Categorical, Integer, Real               4177                   8   1995   \n",
       "2          Categorical, Integer              48842                  14   1996   \n",
       "3    Categorical, Integer, Real                798                  38          \n",
       "4                   Categorical              37711                 294   1998   \n",
       "..                           ...                ...                 ...    ...  \n",
       "584                                          12684                  23   2020   \n",
       "585                        Real                 48                 321   2020   \n",
       "586                        Real                731                1068   2021   \n",
       "587                        Real                731                1068   2021   \n",
       "588                        Real                557                   5   2021   \n",
       "\n",
       "[589 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataframe\n",
    "df = pd.DataFrame({'Dataset Name': name,\n",
    "                        'Data Type': data_type,\n",
    "                        'Task': task,\n",
    "                        'Attribute Type': attribute,\n",
    "                        'Number of Instance': instance,\n",
    "                        'Number of Attribute': n_attribute,\n",
    "                        'Year': year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
